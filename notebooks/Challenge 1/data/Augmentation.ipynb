{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["O8rgDR4PDgS2","WzdkMT3nV3XS","hg_jO_SK1Tvz","WHyyBKa71fWN","w_WnmDH91iBm","_bhisZqrbf5q","jlVNSr-zbtbm","ElLr-XrC1kix","uHUilN_f7LeL","EQ27MZHY8c0C"],"authorship_tag":"ABX9TyM+VjG1hfQwsaqK8vst/bl3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install keras_cv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M87H0BWa_0TJ","executionInfo":{"status":"ok","timestamp":1699716703543,"user_tz":-60,"elapsed":8865,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"8c4cb1b9-42d1-49e2-a283-a92bd7787432"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers as tfkl\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","import os\n","import gc\n","import shutil\n","import keras_cv\n","import cv2\n","\n","input_shape = (96, 96, 3)"],"metadata":{"id":"LqSid7MfyxL-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mounting, Reading clean dataset, and Label creation"],"metadata":{"id":"O8rgDR4PDgS2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive/My Drive/[2023-2024] AN2DL/Challenge 1/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCrKQ6eT0AJa","executionInfo":{"status":"ok","timestamp":1699907609283,"user_tz":-60,"elapsed":16129,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"d09b192a-1fe3-4890-b219-2c2045382e24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive/My Drive/[2023-2024] AN2DL/Challenge 1\n"]}]},{"cell_type":"code","source":["data = np.load('Data/clean_data.npz', allow_pickle=True)\n","imgs, labels_str = data[\"data\"], data[\"labels\"]\n","print(imgs.shape, labels_str.shape)\n","input_shape = imgs.shape[1:]\n","input_shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIe-LL-q0Dlk","executionInfo":{"status":"ok","timestamp":1699907621427,"user_tz":-60,"elapsed":12152,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"f8ceb6a8-c32c-4f60-d9e0-ed993c439701"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(5004, 96, 96, 3) (5004,)\n"]},{"output_type":"execute_result","data":{"text/plain":["(96, 96, 3)"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Augmentation Helper Functions"],"metadata":{"id":"WzdkMT3nV3XS"}},{"cell_type":"code","source":["def random_perspective_transform(image, intensity=0.23):\n","    h, w = image.shape[:2]\n","\n","    # Four corners of the image\n","    pts1 = np.float32([[0, 0], [w, 0], [0, h], [w, h]])\n","\n","    # Random shifts for four corners\n","    pts2 = np.float32([\n","        [np.random.uniform(-intensity, intensity) * w, np.random.uniform(-intensity, intensity) * h],\n","        [w + np.random.uniform(-intensity, intensity) * w, np.random.uniform(-intensity, intensity) * h],\n","        [np.random.uniform(-intensity, intensity) * w, h + np.random.uniform(-intensity, intensity) * h],\n","        [w + np.random.uniform(-intensity, intensity) * w, h + np.random.uniform(-intensity, intensity) * h]\n","    ])\n","\n","    # Compute the perspective transform matrix and apply it to the image\n","    M = cv2.getPerspectiveTransform(pts1, pts2)\n","    transformed_image = cv2.warpPerspective(image, M, (w, h))\n","\n","    return transformed_image\n","\n","def random_perspective_transform_tf(image, intensity=0.2):\n","    # Reformat from batch to image\n","    image_np = image[0, ...]\n","    transformed_image_np = random_perspective_transform(image_np, intensity)\n","    return transformed_image_np[np.newaxis, ...]\n","\n","# Create a Lambda layer for the perspective transformation\n","perspective_layer = tf.keras.layers.Lambda(lambda x: tf.numpy_function(\n","    random_perspective_transform_tf, [x], tf.float32))"],"metadata":{"id":"G1TTjqruV0Pp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Augmentation Models"],"metadata":{"id":"hg_jO_SK1Tvz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ZnNW64yythn"},"outputs":[],"source":["height = width = 96\n","\n","augment_model_1 = tf.keras.Sequential([\n","    tfkl.RandomFlip(\"horizontal\"),\n","    tfkl.RandomTranslation(0.12, 0.12),\n","])\n","\n","augment_model_2 = tf.keras.Sequential([\n","    tfkl.RandomRotation(0.14),\n","    tfkl.RandomZoom(0.07)  # Slight zoom\n","])\n","\n","augment_model_4 = tf.keras.Sequential([\n","    tfkl.RandomTranslation(0.08, 0.08),\n","    tfkl.RandomFlip(\"vertical\"),\n","])\n","\n","augment_model_4a = tf.keras.Sequential([\n","    tfkl.RandomRotation(0.15),\n","    tfkl.RandomFlip(\"vertical\"),\n","])\n","\n","augment_model_5 = tf.keras.Sequential([\n","    perspective_layer\n","])\n","\n","augment_models = [augment_model_1, augment_model_2, augment_model_4a, augment_model_5]"]},{"cell_type":"markdown","source":["# Augmentation Functions"],"metadata":{"id":"WHyyBKa71fWN"}},{"cell_type":"code","source":["def augment_unhealthy(images, augment_models):\n","    # Create an empty array to hold the augmented images\n","    augmented_images = np.zeros_like(images)\n","\n","    # Loop through each image in the input array\n","    for i, img in enumerate(images):\n","        # Randomly select an augmentation model\n","        model = np.random.choice(augment_models)\n","        # Apply augmentation and store in the augmented_images array\n","        augmented_images[i] = model(img[np.newaxis, ...], training=True).numpy()\n","\n","    return augmented_images"],"metadata":{"id":"TRwO0LjA0QfT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_augmented_dataset(images, labels, target_size, augment_models):\n","    # Calculate how many of each class are needed\n","    class_counts = dict(zip(*np.unique(labels, return_counts=True)))\n","    additional_per_class = (target_size // 2) - class_counts[0]\n","\n","    # Containers for the augmented images and labels\n","    augmented_images = []\n","    augmented_labels = []\n","\n","    threshold = target_size // 2\n","\n","    # Continue until we have enough images of each class\n","    while additional_per_class > 0:\n","        for img, label in zip(images, labels):\n","            # Randomly select an augmentation model\n","            model = np.random.choice(augment_models)\n","\n","            # Apply augmentation - Batches are required so I reshape img to (1, 96, 96, 3), and then take the first output\n","            aug_img = model(img[np.newaxis, ...], training=True).numpy()[0]\n","\n","            # Add to the dataset\n","            augmented_images.append(aug_img)\n","            augmented_labels.append(label)\n","\n","            # Update counts and check if we have enough\n","            class_counts[label] += 1\n","            additional_per_class = (threshold) - class_counts[0]\n","            if class_counts[0] >= threshold and class_counts[1] >= threshold:\n","                break\n","\n","    # Combine original and augmented data\n","    final_images = np.concatenate((images, np.array(augmented_images)), axis=0)\n","    final_labels = np.concatenate((labels, np.array(augmented_labels)), axis=0)\n","\n","    # Shuffle the dataset to ensure it's well mixed\n","    indices = np.arange(final_images.shape[0])\n","    np.random.shuffle(indices)\n","    final_images = final_images[indices]\n","    final_labels = final_labels[indices]\n","\n","    return final_images, final_labels"],"metadata":{"id":"LcG6PKhEy144"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Optimize image augmentation to stay beneath colab ram limits\n","def batch_augment_images_to_target(images, labels, augment_models, target_size, batch_size, output_dir):\n","    # Calculate initial class distribution\n","    unique, counts = np.unique(labels, return_counts=True)\n","    class_distribution = dict(zip(unique, counts))\n","\n","    # Determine additional images needed to reach target size while maintaining distribution\n","    additional_images_needed = target_size - len(images)\n","    additional_per_class = {label: additional_images_needed // len(unique) for label in unique}\n","\n","    # Create output directory if it doesn't exist\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    # Containers for augmented images and labels\n","    augmented_images = []\n","    augmented_labels = []\n","\n","    # Batch augmentation loop\n","    batch_counter = 0\n","    while sum(additional_per_class.values()) > 0:\n","        # Loop through each image and label\n","        for img, label in zip(images, labels):\n","            if additional_per_class[label] > 0:\n","                # Randomly select an augmentation model and apply it\n","                model = np.random.choice(augment_models)\n","                augmented_img = model(img[np.newaxis, ...], training=True).numpy()[0]\n","\n","                # Append the augmented image and label\n","                augmented_images.append(augmented_img)\n","                augmented_labels.append(label)\n","\n","                # Decrement the count for the class\n","                additional_per_class[label] -= 1\n","\n","                # If we've built up a full batch, save and clear the batch\n","                if len(augmented_images) == batch_size:\n","                    batch_path = os.path.join(output_dir, f'augmented_batch_{batch_counter}.npz')\n","                    np.savez(batch_path, data=np.array(augmented_images), labels=np.array(augmented_labels))\n","                    print(f\"Batch {batch_counter} saved to {batch_path}\")  # Debug print\n","                    augmented_images = []\n","                    augmented_labels = []\n","                    batch_counter += 1\n","                    gc.collect()  # Collect garbage to free memory\n","\n","        # Shuffle the original dataset for the next pass\n","        indices = np.arange(len(images))\n","        np.random.shuffle(indices)\n","        images = images[indices]\n","        labels = labels[indices]\n","\n","    # Save any remaining images that didn't make up a full batch\n","    if augmented_images:\n","        batch_path = os.path.join(output_dir, f'augmented_batch_{batch_counter}.npz')\n","        np.savez(batch_path, data=np.array(augmented_images), labels=np.array(augmented_labels))\n","        print(f\"Batch {batch_counter} saved to {batch_path}\")  # Debug print\n","        gc.collect()  # Collect garbage to free memory"],"metadata":{"id":"w7OA_awz6Gjw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset balancing (Optional)"],"metadata":{"id":"w_WnmDH91iBm"}},{"cell_type":"code","source":["labels = (labels_str == \"unhealthy\").astype(\"int\")"],"metadata":{"id":"LPCN9RYTjIWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Shuffle original dataset before any operation\n","indices = np.arange(len(labels))\n","np.random.shuffle(indices)\n","imgs = imgs[indices]\n","labels = labels[indices]"],"metadata":{"id":"mkMOHiSV0dnn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(imgs, labels, test_size=.2)\n","X_train.shape, y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qWAQSd4PfPfy","executionInfo":{"status":"ok","timestamp":1699747179970,"user_tz":-60,"elapsed":478,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"e598dd52-226f-4255-abcf-a37c68aa7869"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4003, 96, 96, 3), (4003,))"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["dataset = ((X_train, y_train), (X_val, y_val))"],"metadata":{"id":"8HMnxCgdg8Vv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["balanced = []\n","for i in range(len(dataset)):\n","  batch = dataset[i]\n","  b_data = batch[0]\n","  b_labels = batch[1]\n","  _, (healthy, unhealthy) = np.unique(b_labels, return_counts=True)\n","  delta = healthy-unhealthy\n","  unhealthy_imgs = b_data[b_labels == 1]\n","\n","  unhealthy_imgs = unhealthy_imgs[np.random.choice(unhealthy, delta, replace=False)]\n","  aug_balance_unhealthy = augment_unhealthy(unhealthy_imgs, augment_models)\n","  unhealthy_imgs.shape\n","\n","  b_data = np.append(b_data, aug_balance_unhealthy, axis=0)\n","  b_labels = np.append(b_labels, np.ones(delta))\n","  balanced.append((b_data, b_labels))\n"],"metadata":{"id":"ldL89P77hHIw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = balanced[0]\n","val = balanced[1]\n","indices = np.arange(len(train[1]))\n","np.random.shuffle(indices)\n","train_imgs = train[0][indices]\n","train_labels = train[1][indices]"],"metadata":{"id":"anZOf6_Gciy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["indices = np.arange(len(val[1]))\n","np.random.shuffle(indices)\n","val_imgs = val[0][indices]\n","val_labels = val[1][indices]"],"metadata":{"id":"MjdPrlMsc-Rl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.savez(\"Data/Augmented/train_balanced.npz\", data=np.array(train_imgs), labels=np.array(train_labels))"],"metadata":{"id":"9zZ2xyJsVwfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.savez(\"Data/Augmented/val_balanced.npz\", data=np.array(val_imgs), labels=np.array(val_labels))"],"metadata":{"id":"v_TruN8vWe-A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_, (n_healthy, n_unhealthy) = np.unique(balanced[0][1], return_counts=True)\n","n_healthy, n_unhealthy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2HuEaTnya_8Y","executionInfo":{"status":"ok","timestamp":1699747189211,"user_tz":-60,"elapsed":12,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"8bd30ffe-9f7a-4e32-869f-70800f3eb7c6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2478, 2478)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["del labels_str\n","del unhealthy_imgs\n","del data\n","del dataset\n","del X_train, X_val, y_train, y_val"],"metadata":{"id":"Q1jBLmOy31-3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_size = len(balanced[0][1]) + len(balanced[1][1])"],"metadata":{"id":"yNFLqMkOlubb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_prop = 0.2\n","train_prop = 0.8\n","(val_prop, train_prop)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJxh5BLwl_FE","executionInfo":{"status":"ok","timestamp":1699747189212,"user_tz":-60,"elapsed":10,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"6917dd44-3812-4e6d-cf45-98b91d35d30b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.2, 0.8)"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["# Dataset splitting"],"metadata":{"id":"_bhisZqrbf5q"}},{"cell_type":"code","source":["labels = (labels_str == \"unhealthy\").astype(\"int\")\n","\n","# Shuffle original dataset before any operation\n","indices = np.arange(len(labels))\n","np.random.shuffle(indices)\n","imgs = imgs[indices]\n","labels = labels[indices]"],"metadata":{"id":"t8X5HHaYbiwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_val, y_train, y_val = train_test_split(imgs, labels, test_size=.2)\n","X_train.shape, y_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuXMBolzbnXC","executionInfo":{"status":"ok","timestamp":1699907623098,"user_tz":-60,"elapsed":282,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"0235164f-96ca-43b7-ff15-0c25f1945ca4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((4003, 96, 96, 3), (4003,))"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Distribution analysis"],"metadata":{"id":"jlVNSr-zbtbm"}},{"cell_type":"code","source":["_, (n_healthy, n_unhealthy) = np.unique(y_train, return_counts=True)\n","(n_healthy, n_unhealthy, ((n_healthy)/len(y_train))*100, ((n_unhealthy)/len(y_train))*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_G3YNREwbvVc","executionInfo":{"status":"ok","timestamp":1699907623099,"user_tz":-60,"elapsed":16,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"056a2abf-7b4f-4a07-b275-ce4081a572fd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2501, 1502, 62.47814139395453, 37.52185860604547)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["_, (n_healthy, n_unhealthy) = np.unique(y_val, return_counts=True)\n","(n_healthy, n_unhealthy, ((n_healthy)/len(y_val))*100, ((n_unhealthy)/len(y_val))*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0BOBIyeBbyaD","executionInfo":{"status":"ok","timestamp":1699907623099,"user_tz":-60,"elapsed":10,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"d0d37c89-9a88-4789-fe7c-7bc94535194a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(600, 401, 59.94005994005994, 40.05994005994006)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["train_imgs = X_train\n","train_labels = y_train"],"metadata":{"id":"_1sUfSNYdQhy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset augmentation (Batched)"],"metadata":{"id":"ElLr-XrC1kix"}},{"cell_type":"code","source":["# Define the size you want for the final dataset\n","target_size = 13000\n","\n","# Call the function to generate the augmented dataset (SAVED TO YOUR DRIVE FOLDER!) - Check if you have enough space first"],"metadata":{"id":"csVPjZ0Kz5-R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train augmentation\n","batch_augment_images_to_target(train_imgs, train_labels, augment_models, target_size=target_size, batch_size=12801, output_dir='Data/Augmented_Experimental/Train/')"],"metadata":{"id":"dID_p6gOmbs-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# \"Manual\" mode (Be wary of RAM usage)"],"metadata":{"id":"uHUilN_f7LeL"}},{"cell_type":"code","source":["augmented_imgs, augmented_labels = create_augmented_dataset(imgs, labels, target_size, augment_models)"],"metadata":{"id":"gPPWP7AN7Te-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(augmented_imgs.shape, augmented_labels.shape)\n","_, (n_healthy, n_unhealthy) = np.unique(augmented_labels, return_counts=True)\n","n_healthy, n_unhealthy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i7jbsXhk5HRc","executionInfo":{"status":"ok","timestamp":1699379244268,"user_tz":-60,"elapsed":249,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"52b7924c-b5ab-4701-8c75-5e165c392a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(26322, 96, 96, 3) (26322,)\n"]},{"output_type":"execute_result","data":{"text/plain":["(13322, 13000)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["np.savez(\"augmented_data_v2.npz\", data=augmented_imgs, labels=augmented_labels)"],"metadata":{"id":"OYQWnogQ50x9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Check Augmentation Results"],"metadata":{"id":"EQ27MZHY8c0C"}},{"cell_type":"code","source":["def plot_random_images(images, labels, num_images=100):\n","    # Select a random subset of images and labels\n","    indices = np.random.choice(range(len(images)), num_images, replace=False)\n","    selected_images = images[indices]\n","    selected_labels = labels[indices]\n","\n","    # Determine the grid size we'll need to plot the images\n","    grid_size = int(np.ceil(np.sqrt(num_images)))\n","\n","    # Set up the matplotlib figure and axes\n","    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n","    axes = axes.flatten()\n","\n","    for img, label, ax in zip(selected_images, selected_labels, axes):\n","        # Display the image\n","        ax.imshow(img.astype('uint8'))\n","        # Set the title to the label of the image\n","        ax.set_title(f\"Label: {label}\")\n","        # Turn off axis markers\n","        ax.axis('off')\n","\n","    # Hide any remaining axes without images\n","    for ax in axes[num_images:]:\n","        ax.axis('off')\n","\n","    # Adjust layout\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"GD5SF46v8f8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aug_batch = 0\n","data = np.load(f'Data/Augmented_Contrast/Validation/augmented_batch_{aug_batch}.npz', allow_pickle=True)\n","aug_imgs, aug_labels = data[\"data\"], data[\"labels\"]"],"metadata":{"id":"JnaZei9o8iLo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["aug_imgs = imgs\n","aug_labels = labels"],"metadata":{"id":"urtIr0Gdk78f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"VOgZnhK5NCIt"}},{"cell_type":"code","source":["plot_random_images(aug_imgs, aug_labels, num_images=25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1eCwPIkA72b8PlCBHHYJyf3QzkK_HfI3G"},"id":"BRYvXBXB87Th","executionInfo":{"status":"ok","timestamp":1699529432919,"user_tz":-60,"elapsed":5557,"user":{"displayName":"Federico Toschi","userId":"03268067091644128077"}},"outputId":"46aba90a-cbc6-4fc1-db82-5d0fcb632844"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}