{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7169244,"sourceType":"datasetVersion","datasetId":4141950},{"sourceId":7249492,"sourceType":"datasetVersion","datasetId":4138370}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Fix randomness and hide warnings\nseed = 42\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\nos.environ['TF_GPU_THREAD_MODE']=\"gpu_private\"\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\nimport numpy as np\nnp.random.seed(seed)\nfrom scipy.interpolate import interp1d\nimport logging\nimport gc\nimport random\nrandom.seed(seed)\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as pyplot\n# Import tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras import backend as K\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)\nfrom tensorflow.keras import mixed_precision\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n#tf.keras.backend.set_floatx('float16')\ntf.function(jit_compile=True)\ntf.keras.backend.floatx()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading - Preprocessing","metadata":{}},{"cell_type":"code","source":"def build_sequences_filtered(target_data, valid_periods, window=200, stride=50, telescope=18):\n    assert window % stride == 0\n    dataset = []\n    labels = []\n    for i, signal in enumerate(target_data):\n        if valid_periods[i][1]-valid_periods[i][0] >= telescope*2:\n            for j in np.arange(min(valid_periods[i][0],len(signal)-window-telescope),len(signal)-window-telescope,stride):\n                input_sequence = signal[j:j+window]\n                output_sequence = signal[j+window:j+window+telescope]\n                dataset.append(input_sequence)\n                labels.append(output_sequence)\n    dataset = np.array(dataset)\n    labels = np.array(labels)\n    medians = np.median(dataset,axis=1)\n    median_labels_telescope = np.median(labels,axis=1)\n    return dataset, labels, medians, median_labels_telescope#, iqr_X, iqr_y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"telescope = 18\nbatch_size = 128\nepochs = 200\nwindow = 200\nstride = 10\ndata = np.load(\"/kaggle/input/time-series-anndl/training_data.npy\")\ncategories = np.load(\"/kaggle/input/time-series-anndl/categories.npy\")\nvalid_periods = np.load(\"/kaggle/input/time-series-anndl/valid_periods.npy\")\nX, y, median_X, median_y = build_sequences_filtered(data, valid_periods, window, stride, telescope)\nnorm_X, norm_y = (X-median_X[:,None]), (y-median_y[:,None])#/iqr_y[:,None]\nprint(X.shape, y.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val, norm_X_train, norm_X_val, norm_y_train, norm_y_val, median_y_train, median_y_val = train_test_split(X, y, norm_X, norm_y, median_y, test_size=0.2, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(X, y, batch_size=128, prefetch_amt=tf.data.experimental.AUTOTUNE):\n    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n    # reshape x from (200) to (200,1) and y from (9) to (9,1)\n    dataset = dataset.map(lambda x, y: (tf.reshape(x, (200,1)), y),num_parallel_calls=tf.data.AUTOTUNE)\n    #dataset = dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(prefetch_amt)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# T2V + GRU Model","metadata":{}},{"cell_type":"code","source":"class T2V(tfkl.Layer):\n    def __init__(self, output_dim=None, **kwargs):\n        self.output_dim = output_dim\n        super(T2V, self).__init__(**kwargs)\n        \n    def build(self, input_shape):\n        self.W = self.add_weight(name='W',shape=(input_shape[-1], self.output_dim),initializer='uniform',trainable=True)\n        self.P = self.add_weight(name='P',shape=(input_shape[1], self.output_dim),initializer='uniform',trainable=True)\n        self.w = self.add_weight(name='w',shape=(input_shape[1], 1),initializer='uniform',trainable=True)\n        self.p = self.add_weight(name='p',shape=(input_shape[1], 1),initializer='uniform',trainable=True)\n        super(T2V, self).build(input_shape)\n        \n    def call(self, x):\n        original = self.w * x + self.p\n        sin_trans = K.sin(K.dot(x, self.W) + self.P)\n        return K.concatenate([sin_trans, original], -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_lstm_model = tfk.Sequential([ #28,312 after 10 epochs\n    # Shape [batch, time, features] => [batch, lstm_units].\n    # Adding more `lstm_units` just overfits more quickly.\n    T2V(16),\n    tfkl.GRU(150, dropout=0.2, return_sequences=True),\n    tfkl.GRU(150, dropout=0.3, return_sequences=False),\n    tfkl.Flatten(),\n    tfkl.Dense(telescope,kernel_initializer=tf.initializers.zeros(), activation=\"gelu\"),\n])\nmulti_lstm_model.compile(loss=tfk.losses.MeanSquaredError(), metrics=['mae'], optimizer=tfk.optimizers.AdamW())\nmulti_lstm_model.build((None,window,1))\nmulti_lstm_model.summary() \nhistory = multi_lstm_model.fit(\n    make_dataset(X_train, y_train, batch_size=batch_size), #normalized_X_train\n    epochs = epochs,\n    validation_data=make_dataset(X_val, y_val, batch_size=batch_size),#(X_val,y_val),# (normalized_X_val,normalized_y_val)\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, min_delta=5e-6, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=4, factor=0.1, min_lr=1e-7)\n    ]\n).history","metadata":{"_kg_hide-output":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(history['val_loss'], label='Custom ResNet', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('MSE')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_lstm_model.evaluate(X_val, y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"multi_lstm_model.save(\"/kaggle/working/T2V_Custom\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r Model.zip /kaggle/working/T2V_Custom","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'Model.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}