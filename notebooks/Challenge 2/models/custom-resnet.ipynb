{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7169244,"sourceType":"datasetVersion","datasetId":4141950}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras import regularizers\nimport tensorflow_addons as tfa\nimport numpy as np\nimport time\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import RobustScaler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed = 42\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\nnp.random.seed(seed)\n\nimport logging\nimport gc\nimport random\nrandom.seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"telescope = 18\nbatch_size = 128\nepochs = 200\nwindow = 200\nstride = 50","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.load(\"../input/time-series-anndl/training_data.npy\")\ncategories = np.load(\"../input/time-series-anndl/categories.npy\")\nvalid_periods = np.load(\"../input/time-series-anndl/valid_periods.npy\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_sequences(target_data, valid_periods, window=200, stride=50, telescope=18):\n    # Sanity check to avoid runtime errors\n    assert window % stride == 0\n    dataset = []\n    labels = []\n    for i, signal in enumerate(target_data):\n        #remove all initial zeros\n        temp_sig = signal[valid_periods[i][0]:]\n        padding_check = (len(temp_sig)-telescope)%window\n        if(padding_check != 0):\n            # Compute padding length\n            padding_len = window - len(temp_sig)%window\n            padding = np.zeros((padding_len), dtype='float32')\n            temp_sig = np.concatenate((padding,temp_sig))\n            assert len(temp_sig) % window == 0\n\n        for j in np.arange(0,len(temp_sig)-window-telescope,stride):\n            dataset.append(temp_sig[j:j+window])\n            labels.append(temp_sig[j+window:j+window+telescope])\n    return np.expand_dims(np.array(dataset),axis=-1), np.expand_dims(np.array(labels),axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = build_sequences(data,valid_periods,window=window,stride=stride,telescope=telescope)\ndel data\nX.shape, y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\ndel X,y\nX_train.shape, X_val.shape, y_train.shape, y_val.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = X_train.shape[1:]\noutput_shape = y_train.shape[1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1D ResNet + Attention","metadata":{}},{"cell_type":"code","source":"def build_resnet(input_shape, output_shape):\n    input_layer = tfk.Input(input_shape)\n    \n    # Reshape to add the feature/channel dimension\n    #input_layer = tfk.layers.Reshape((200, 1))(input_layer)\n        \n    n_feature_maps = 64\n\n    #input_layer = keras.layers.Input(input_shape)\n\n    # BLOCK 1\n\n    conv_x = tfkl.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n    conv_x = tfkl.BatchNormalization()(conv_x)\n    conv_x = tfkl.Activation('relu')(conv_x)\n\n    conv_y = tfkl.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n    conv_y = tfkl.BatchNormalization()(conv_y)\n    conv_y = tfkl.Activation('relu')(conv_y)\n\n    conv_z = tfkl.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n    conv_z = tfkl.BatchNormalization()(conv_z)\n\n    # expand channels for the sum\n    shortcut_y = tfkl.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n    shortcut_y = tfkl.BatchNormalization()(shortcut_y)\n\n    output_block_1 = tfkl.add([shortcut_y, conv_z])\n    output_block_1 = tfkl.Activation('relu')(output_block_1)\n\n    # BLOCK 2\n\n    conv_x = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n    conv_x = tfkl.BatchNormalization()(conv_x)\n    conv_x = tfkl.Activation('relu')(conv_x)\n\n    conv_y = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n    conv_y = tfkl.BatchNormalization()(conv_y)\n    conv_y = tfkl.Activation('relu')(conv_y)\n\n    conv_z = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n    conv_z = tfkl.BatchNormalization()(conv_z)\n\n    # expand channels for the sum\n    shortcut_y = tfkl.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n    shortcut_y = tfkl.BatchNormalization()(shortcut_y)\n\n    output_block_2 = tfkl.add([shortcut_y, conv_z])\n    output_block_2 = tfkl.Activation('relu')(output_block_2)\n\n    attention_probs = tfk.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same', activation='softmax')(output_block_2)\n    attention_mul = tfk.layers.Multiply()([output_block_2, attention_probs])\n    \n    gap_layer = tfk.layers.GlobalAveragePooling1D()(attention_mul)\n    output_layer = tfk.layers.Dense(output_shape[0], activation='gelu')(gap_layer)\n\n    model = tfk.models.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.AdamW())\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"def make_dataset(X, y, batch_size=128, prefetch_amt=tf.data.experimental.AUTOTUNE):\n    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n    # reshape x from (200) to (200,1) and y from (9) to (9,1)\n    dataset = dataset.map(lambda x, y: (tf.reshape(x, (200,1)), tf.reshape(y, (18,1))),num_parallel_calls=tf.data.AUTOTUNE)\n    #dataset = dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(prefetch_amt)\n    return dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import mixed_precision\n\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\ntf.function(jit_compile=True) \ntf.keras.backend.floatx()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_resnet(input_shape, output_shape)\nmodel.summary()\ntfk.utils.plot_model(model, expand_nested=True, show_shapes=True)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    make_dataset(X_train, y_train, batch_size=batch_size),\n    validation_data=make_dataset(X_val, y_val, batch_size=batch_size),\n    batch_size = batch_size,\n    epochs = epochs,\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', min_delta=5e-6, patience=7, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=5, factor=0.1)\n    ]\n).history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(history['loss'], alpha=.3, color='#4D61E2', linestyle='--')\nplt.plot(history['val_loss'], label='Custom ResNet', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('MSE')\nplt.grid(alpha=.3)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/ResNet_Custom\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r Model.zip /kaggle/working/ResNet_Custom","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'Model.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}