{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7249492,"sourceType":"datasetVersion","datasetId":4138370}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Ensemble model: averaging predictions of GRU and DLinear\nBoth trained on normalized data\nfinal predictions are summed with the predicted median","metadata":{}},{"cell_type":"markdown","source":"## Dataset Loading and Libraries","metadata":{}},{"cell_type":"code","source":"# Fix randomness and hide warnings\nseed = 42\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['PYTHONHASHSEED'] = str(seed)\nos.environ['MPLCONFIGDIR'] = os.getcwd()+'/configs/'\nos.environ['TF_GPU_THREAD_MODE']=\"gpu_private\"\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\nwarnings.simplefilter(action='ignore', category=Warning)\nimport numpy as np\nnp.random.seed(seed)\nfrom scipy.interpolate import interp1d\nimport logging\nimport gc\nimport random\nrandom.seed(seed)\nimport pandas as pd\nimport seaborn as sns\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nplt.rc('font', size=16)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as pyplot\n# Import tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras import backend as K\ntf.autograph.set_verbosity(0)\ntf.get_logger().setLevel(logging.ERROR)\ntf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)\nprint(tf.__version__)\nfrom tensorflow.keras import mixed_precision\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n#tf.keras.backend.set_floatx('float16')\ntf.function(jit_compile=True)\ntf.keras.backend.floatx()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-21T20:15:55.975367Z","iopub.execute_input":"2023-12-21T20:15:55.975984Z","iopub.status.idle":"2023-12-21T20:16:08.684161Z","shell.execute_reply.started":"2023-12-21T20:15:55.975952Z","shell.execute_reply":"2023-12-21T20:16:08.683171Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"2.13.0\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'float32'"},"metadata":{}}]},{"cell_type":"code","source":"def build_sequences_filtered(target_data, valid_periods, window=200, stride=50, telescope=18):\n    assert window % stride == 0\n    outlier_detection_length = 50\n    delta = 0.0001\n    outliers = []\n    dataset = []\n    labels = []\n    for i, signal in enumerate(target_data):\n        if valid_periods[i][1]-valid_periods[i][0] >= telescope*2:\n            for j in np.arange(min(valid_periods[i][0],len(signal)-window-telescope),len(signal)-window-telescope,stride):\n                input_sequence = signal[j:j+window]\n                output_sequence = signal[j+window:j+window+telescope]\n                #grad_less_delta = np.abs(np.ediff1d(input_sequence)) < delta\n                #grad_less_delta = np.abs(np.gradient(input_sequence)) < delta\n                # Now we have an array of 0s and 1s\n                #temp = np.diff(np.where(np.concatenate(([grad_less_delta[0]],grad_less_delta[:-1] != grad_less_delta[1:],[True])))[0])[::2]\n                # If temp contains at least one value that is greater than outlier_detection_length, then we have an outlier\n                #if np.any(temp > outlier_detection_length):# or in_iqr==0 or out_iqr==0:\n                    #outliers.append(i)\n                #else:\n                dataset.append(input_sequence)\n                labels.append(output_sequence)\n    dataset = np.array(dataset)\n    labels = np.array(labels)\n    medians = np.median(dataset,axis=1)\n    median_labels_telescope = np.median(labels,axis=1)\n    print(len(outliers))\n    return dataset, labels, medians, median_labels_telescope#, iqr_X, iqr_y","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:04:28.679707Z","iopub.execute_input":"2023-12-21T21:04:28.680765Z","iopub.status.idle":"2023-12-21T21:04:28.692644Z","shell.execute_reply.started":"2023-12-21T21:04:28.680727Z","shell.execute_reply":"2023-12-21T21:04:28.691599Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"telescope = 18\nbatch_size = 128\nepochs = 200\nwindow = 200\nstride = 10\ndata = np.load(\"/kaggle/input/timeseries/training_data.npy\")\ncategories = np.load(\"/kaggle/input/timeseries/categories.npy\")\nvalid_periods = np.load(\"/kaggle/input/timeseries/valid_periods.npy\")\nX, y, median_X, median_y = build_sequences_filtered(data, valid_periods, window, stride, telescope)\nnorm_X, norm_y = (X-median_X[:,None]), (y-median_y[:,None])#/iqr_y[:,None]\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:04:35.886858Z","iopub.execute_input":"2023-12-21T21:04:35.887569Z","iopub.status.idle":"2023-12-21T21:04:38.042690Z","shell.execute_reply.started":"2023-12-21T21:04:35.887532Z","shell.execute_reply":"2023-12-21T21:04:38.041709Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"0\n(219985, 200) (219985, 18)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Detecting outliers and splits","metadata":{}},{"cell_type":"code","source":"max_telescope_grads = np.abs(np.diff(y,axis=1))\ncount_telescope = np.sum(max_telescope_grads >= 0.6, axis=1)\nprint(count_telescope.shape)\nindices_telescope = np.where((count_telescope!=1))[0]\nmax_window_grads = np.abs(np.diff(X,axis=1))\ncount_window = np.sum(max_window_grads >= 0.6, axis = 1)\nindices_window = np.where((count_window > 2) | (count_window < 1))[0]\n\nidx = np.intersect1d(indices_window, indices_telescope)\nprint(\"outliers window:\",len(X)-len(indices_window))\nprint(\"outliers telscope:\",len(y)-len(indices_telescope))\nprint(\"total intersect outliers:\", len(y)-len(idx))\nnp.where((count_telescope==1))[0][40:80]","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:16:27.679672Z","iopub.execute_input":"2023-12-21T20:16:27.680051Z","iopub.status.idle":"2023-12-21T20:16:28.059084Z","shell.execute_reply.started":"2023-12-21T20:16:27.680011Z","shell.execute_reply":"2023-12-21T20:16:28.058190Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(219527,)\noutliers window: 8012\noutliers telscope: 924\ntotal intersect outliers: 8760\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([14380, 14381, 15340, 15341, 15379, 15380, 15391, 15392, 15599,\n       15628, 16327, 16438, 17693, 17694, 17739, 17740, 19815, 19816,\n       20167, 20168, 20347, 20515, 20518, 20519, 21084, 21085, 22258,\n       22260, 22262, 22263, 22269, 22270, 23012, 23013, 23830, 23831,\n       25171, 25347, 25356, 25357])"},"metadata":{}}]},{"cell_type":"code","source":"max_telescope_grads = np.max(np.abs(np.diff(y,axis=1)),axis=1)\nmax_window_grads = np.max(np.abs(np.diff(X,axis=1)),axis=1)\nindices = np.where((max_telescope_grads >= 1.8*max_window_grads) & (max_window_grads>=0.2))[0]\nconstant_samples_mask = np.all(y[:, 1:] == y[:, :-1], axis=1)\n# Get indices of constant samples\nconstant_telescope_indices = np.where(constant_samples_mask)[0]\n#idx = np.intersect1d(indices_window, indices_telescope)\nprint(\"outliers window:\",len(indices))\nprint(\"outliers telscope:\",len(indices))\nprint(\"total intersect outliers:\", len(indices))\nprint(\"total constant telescopes: \",len(constant_telescope_indices))\nindices, constant_telescope_indices","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:16:28.060359Z","iopub.execute_input":"2023-12-21T20:16:28.060756Z","iopub.status.idle":"2023-12-21T20:16:28.425717Z","shell.execute_reply.started":"2023-12-21T20:16:28.060719Z","shell.execute_reply":"2023-12-21T20:16:28.424747Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"outliers window: 470\noutliers telscope: 470\ntotal intersect outliers: 470\ntotal constant telescopes:  93\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(array([  4267,   4268,   4318,   4319,   5510,   5511,   6094,   6095,\n          6155,   6156,   6964,   7788,   8656,   8657,  10285,  10286,\n         10620,  10621,  10767,  14380,  14381,  14397,  14398,  15651,\n         16671,  23344,  23345,  23448,  23449,  23830,  23831,  25266,\n         25423,  25429,  25430,  25469,  25470,  25628,  25776,  25922,\n         25923,  26062,  27628,  27629,  27759,  27760,  29341,  29342,\n         29375,  29376,  31027,  31028,  31036,  31037,  31290,  31738,\n         34697,  34698,  35936,  35959,  35960,  35973,  36196,  36197,\n         36222,  36250,  36251,  36278,  36279,  36331,  36443,  36444,\n         37155,  37156,  37714,  37846,  38097,  38101,  38302,  38303,\n         38311,  38418,  38482,  38558,  41310,  41311,  41449,  41450,\n         41485,  41994,  42089,  42090,  42355,  42356,  42902,  42903,\n         42942,  42948,  42949,  43284,  43298,  43379,  43591,  45332,\n         45489,  45517,  45518,  45531,  45670,  45807,  49398,  51639,\n         52855,  53645,  53832,  53833,  53885,  53952,  53953,  54145,\n         54344,  54345,  54376,  54456,  54457,  54513,  54622,  54623,\n         54882,  54883,  55469,  55470,  55503,  55567,  55593,  55602,\n         55603,  55678,  55679,  55868,  55916,  55917,  55931,  56058,\n         56065,  56147,  57164,  57394,  57395,  57818,  57819,  58880,\n         58881,  59032,  60031,  60131,  60132,  60148,  60165,  60490,\n         60495,  60496,  64816,  64817,  80947,  81400,  81612,  81831,\n         82050,  82051,  82076,  82077,  82622,  82623,  82849,  83224,\n         83225,  83262,  83993,  84705,  85608,  85618,  86921,  87094,\n         87095,  87129,  87130,  87164,  87165,  87620,  89974,  89975,\n         90892,  90893,  90912,  90927,  90943,  91014,  91015,  91024,\n         91155,  91294,  91712,  92014,  92015,  93058,  93059,  93697,\n         93698,  93735,  93736,  94071,  94103,  94279,  94280,  94288,\n         94289,  94394,  94501,  94747,  94848,  94849,  95017,  95089,\n         95098,  95099,  95115,  95153,  95296,  95314,  95315,  95340,\n         95380,  95381,  95560,  95586,  95587,  96744,  96745,  96751,\n         96752,  96845,  96846,  96856,  96857,  99556,  99823,  99824,\n        103916, 105055, 105115, 106133, 106779, 107637, 107777, 107784,\n        107889, 108001, 108064, 108183, 108246, 108748, 108911, 109914,\n        110253, 110281, 110351, 110547, 110928, 111256, 111773, 112596,\n        112610, 112694, 112736, 112764, 112771, 112785, 112806, 113701,\n        113918, 113925, 114219, 114749, 114756, 114805, 115540, 115764,\n        125945, 125946, 133860, 133861, 139435, 142306, 142599, 142600,\n        142655, 142656, 147453, 147454, 148975, 158226, 158227, 158255,\n        158256, 159730, 160954, 160955, 168981, 168982, 169831, 169832,\n        170011, 171021, 171522, 171533, 171632, 171633, 171661, 171662,\n        171701, 171925, 172035, 172036, 172459, 172460, 172663, 172664,\n        174507, 175287, 175345, 175346, 175394, 175395, 176193, 176194,\n        176303, 176483, 177172, 177326, 177327, 178275, 178276, 178308,\n        178309, 178387, 178412, 179453, 179569, 179570, 179657, 179658,\n        180112, 180204, 180205, 180213, 180319, 180325, 181015, 181759,\n        183190, 183191, 183496, 186470, 186471, 187913, 187914, 188279,\n        188280, 188459, 188674, 194859, 194860, 199015, 199912, 202529,\n        202641, 202667, 202775, 203265, 204183, 205457, 205458, 205718,\n        205719, 205850, 205851, 206048, 206144, 206516, 206517, 207301,\n        207302, 207855, 208033, 208040, 208516, 208531, 208532, 208757,\n        208758, 208771, 208772, 208786, 208787, 208840, 208960, 208961,\n        209027, 209028, 209179, 209184, 209185, 209251, 209252, 209341,\n        209342, 209348, 209349, 209365, 209366, 209414, 209420, 209464,\n        209466, 209467, 209543, 209643, 209655, 209656, 209700, 209724,\n        209814, 209830, 209831, 210058, 210096, 210257, 210258, 210305,\n        210522, 210620, 211332, 211931, 211932, 212429, 214300, 214301,\n        214328, 214452, 214484, 214485, 215415, 215416, 215466, 215467,\n        215594, 215603, 215717, 215718, 215979, 215980, 216199, 216267,\n        216268, 217329, 217330, 217534, 217535, 218617]),\n array([  2449,   2450,   3248,   3249,   3252,   3257,   3260,   3261,\n          3262,   3263,   3371,   4838,   4840,   4841,   4842,   4843,\n          4844,   4845,   4846,   4847,   4848,   4849,  57504,  57505,\n         57506,  65230,  65234,  65236,  65238,  65240,  65241,  65261,\n         65275,  65276,  65283,  65284,  65355,  65367,  65368,  65369,\n         65370,  65371,  65372,  96330,  96335, 101448, 101449, 152817,\n        157210, 157212, 157458, 157459, 158795, 158796, 158797, 158798,\n        158799, 181947, 181948, 183579, 183580, 183586, 183587, 183805,\n        183806, 183807, 193013, 193014, 193016, 203565, 205182, 205183,\n        207502, 207509, 207510, 212081, 212082, 212083, 212084, 213259,\n        213360, 213361, 213362, 213363, 213364, 213421, 213422, 213423,\n        213424, 213425, 213780, 213782, 215281]))"},"metadata":{}}]},{"cell_type":"code","source":"plt.plot(range(200),X[157212],color='blue')\nplt.plot(range(200,218),y[157212],color='red')","metadata":{"execution":{"iopub.status.busy":"2023-12-21T18:24:13.999504Z","iopub.execute_input":"2023-12-21T18:24:14.000356Z","iopub.status.idle":"2023-12-21T18:24:14.191326Z","shell.execute_reply.started":"2023-12-21T18:24:14.000321Z","shell.execute_reply":"2023-12-21T18:24:14.190502Z"},"trusted":true},"execution_count":105,"outputs":[{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7b68d00391e0>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"'''idx = np.union1d(indices, constant_telescope_indices)\nidx = np.setdiff1d(range(len(X)), idx)\nX=X[idx]\ny=y[idx]\nmedian_y = median_y[idx]\nmedian_X = median_X[idx]\nnorm_X = norm_X[idx]\nnorm_y = norm_y[idx]'''\nX_train, X_val, y_train, y_val, norm_X_train, norm_X_val, norm_y_train, norm_y_val, median_y_train, median_y_val = train_test_split(X, y, norm_X, norm_y, median_y, test_size=0.2, random_state=42)\nprint(X.shape, y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:04:52.308096Z","iopub.execute_input":"2023-12-21T21:04:52.308469Z","iopub.status.idle":"2023-12-21T21:04:52.623777Z","shell.execute_reply.started":"2023-12-21T21:04:52.308439Z","shell.execute_reply":"2023-12-21T21:04:52.622838Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"(219985, 200) (219985, 18)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## DLinear","metadata":{}},{"cell_type":"code","source":"class DLinear(tfk.models.Model):\n    def __init__(self, output_steps, kernel_size=25, **kwargs):\n        super(DLinear, self).__init__(**kwargs)\n        self.kernel_size = kernel_size\n        self.output_steps = output_steps\n        self.kernel_initializer = \"he_normal\"\n        \n    def build(self, input_shape):\n        self.built_input_shape = input_shape\n        #self.td1 = tfkl.Dense(512,kernel_initializer=self.kernel_initializer,name=\"trend_dense\")\n        #self.rd1 = tfkl.Dense(512,kernel_initializer=self.kernel_initializer,name=\"residual_dense\")\n        self.trend_dense = tfkl.Dense(self.output_steps,kernel_initializer=self.kernel_initializer,name=\"trend_recomposer\")\n        self.residual_dense = tfkl.Dense(self.output_steps,kernel_initializer=self.kernel_initializer,name=\"residual_recomposer\")\n        super(DLinear, self).build(input_shape)\n        \n    def call(self, inputs):\n        trend_input = tf.expand_dims(inputs,axis=-1)\n        trend = tfkl.AveragePooling1D(pool_size=self.kernel_size,strides=1,padding=\"same\",name=\"trend_decomposer\")(trend_input)\n        trend = tf.squeeze(trend,axis=-1)\n        residual = tfkl.Subtract(name=\"residual_decomposer\")([inputs, trend])\n        \n        #trend = self.td1(trend)\n        #residual = self.rd1(residual)\n        \n        residual = self.residual_dense(residual)\n        trend = self.trend_dense(trend)\n        add = tfkl.Add(name=\"recomposer\")([residual, trend])\n        return add\n    \n    def summary(self):\n        if self.built:\n            self.model().summary()\n        else:\n            super().summary()\n            \n    def model(self):\n        x = tfkl.Input(shape=(self.built_input_shape[1:]))\n        model = tfk.models.Model(inputs=[x],outputs=self.call(x))\n        return model","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:04:57.733457Z","iopub.execute_input":"2023-12-21T21:04:57.734207Z","iopub.status.idle":"2023-12-21T21:04:57.745851Z","shell.execute_reply.started":"2023-12-21T21:04:57.734177Z","shell.execute_reply":"2023-12-21T21:04:57.744702Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model_dlinear = DLinear(telescope, kernel_size=25)\nmodel_dlinear.build((None,window))\nmodel_dlinear.compile(loss=tf.keras.losses.MeanSquaredError(), metrics=['mae'], optimizer=tf.keras.optimizers.Adam(1e-3))\nmodel_dlinear.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:05:03.395360Z","iopub.execute_input":"2023-12-21T21:05:03.395747Z","iopub.status.idle":"2023-12-21T21:05:03.500297Z","shell.execute_reply.started":"2023-12-21T21:05:03.395717Z","shell.execute_reply":"2023-12-21T21:05:03.499370Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_2 (InputLayer)        [(None, 200)]                0         []                            \n                                                                                                  \n tf.expand_dims_1 (TFOpLamb  (None, 200, 1)               0         ['input_2[0][0]']             \n da)                                                                                              \n                                                                                                  \n trend_decomposer (AverageP  (None, 200, 1)               0         ['tf.expand_dims_1[0][0]']    \n ooling1D)                                                                                        \n                                                                                                  \n tf.compat.v1.squeeze_1 (TF  (None, 200)                  0         ['trend_decomposer[0][0]']    \n OpLambda)                                                                                        \n                                                                                                  \n residual_decomposer (Subtr  (None, 200)                  0         ['input_2[0][0]',             \n act)                                                                'tf.compat.v1.squeeze_1[0][0]\n                                                                    ']                            \n                                                                                                  \n residual_recomposer (Dense  (None, 18)                   3618      ['residual_decomposer[0][0]'] \n )                                                                                                \n                                                                                                  \n trend_recomposer (Dense)    (None, 18)                   3618      ['tf.compat.v1.squeeze_1[0][0]\n                                                                    ']                            \n                                                                                                  \n recomposer (Add)            (None, 18)                   0         ['residual_recomposer[0][0]', \n                                                                     'trend_recomposer[0][0]']    \n                                                                                                  \n==================================================================================================\nTotal params: 7236 (28.27 KB)\nTrainable params: 7236 (28.27 KB)\nNon-trainable params: 0 (0.00 Byte)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Median regressor (dense)","metadata":{}},{"cell_type":"code","source":"median_regressor = tfk.Sequential()\nmedian_regressor.add(tfkl.Dense(200, activation = 'relu', input_shape=(200,)))\nmedian_regressor.add(tfkl.Dense(400, activation='relu'))\nmedian_regressor.add(tfkl.Dense(400, activation='relu'))\nmedian_regressor.add(tfkl.Dense(200, activation='relu'))\nmedian_regressor.add(tfkl.Dense(1, activation='sigmoid'))\nmedian_regressor.compile(optimizer=tf.keras.optimizers.AdamW(1e-3), loss='mean_squared_error', metrics=['mae'])  # Using mean squared error as the loss function\nmedian_regressor.summary()","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:05:00.642547Z","iopub.execute_input":"2023-12-21T21:05:00.643316Z","iopub.status.idle":"2023-12-21T21:05:00.742119Z","shell.execute_reply.started":"2023-12-21T21:05:00.643285Z","shell.execute_reply":"2023-12-21T21:05:00.741254Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense_6 (Dense)             (None, 200)               40200     \n                                                                 \n dense_7 (Dense)             (None, 400)               80400     \n                                                                 \n dense_8 (Dense)             (None, 400)               160400    \n                                                                 \n dense_9 (Dense)             (None, 200)               80200     \n                                                                 \n dense_10 (Dense)            (None, 1)                 201       \n                                                                 \n=================================================================\nTotal params: 361401 (1.38 MB)\nTrainable params: 361401 (1.38 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training of DLinear and Median predictor","metadata":{}},{"cell_type":"code","source":"# Train the model\nhistory = model_dlinear.fit(\n    x = norm_X_train,\n    y = norm_y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(norm_X_val,norm_y_val),\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, min_delta=1e-5, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=4, factor=0.1)\n    ]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:05:11.762650Z","iopub.execute_input":"2023-12-21T21:05:11.763483Z","iopub.status.idle":"2023-12-21T21:07:07.462965Z","shell.execute_reply.started":"2023-12-21T21:05:11.763444Z","shell.execute_reply":"2023-12-21T21:07:07.462000Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Epoch 1/200\n1375/1375 [==============================] - 7s 4ms/step - loss: 0.0053 - mae: 0.0452 - val_loss: 0.0043 - val_mae: 0.0411 - lr: 0.0010\nEpoch 2/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0043 - mae: 0.0406 - val_loss: 0.0043 - val_mae: 0.0407 - lr: 0.0010\nEpoch 3/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0043 - mae: 0.0406 - val_loss: 0.0043 - val_mae: 0.0405 - lr: 0.0010\nEpoch 4/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0043 - mae: 0.0407 - val_loss: 0.0043 - val_mae: 0.0412 - lr: 0.0010\nEpoch 5/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0043 - mae: 0.0407 - val_loss: 0.0044 - val_mae: 0.0413 - lr: 0.0010\nEpoch 6/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0397 - val_loss: 0.0042 - val_mae: 0.0400 - lr: 1.0000e-04\nEpoch 7/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0397 - val_loss: 0.0042 - val_mae: 0.0400 - lr: 1.0000e-04\nEpoch 8/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0397 - val_loss: 0.0042 - val_mae: 0.0400 - lr: 1.0000e-04\nEpoch 9/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0396 - val_loss: 0.0042 - val_mae: 0.0399 - lr: 1.0000e-04\nEpoch 10/200\n1375/1375 [==============================] - 5s 3ms/step - loss: 0.0042 - mae: 0.0397 - val_loss: 0.0042 - val_mae: 0.0401 - lr: 1.0000e-04\nEpoch 11/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-05\nEpoch 12/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0399 - lr: 1.0000e-05\nEpoch 13/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0399 - lr: 1.0000e-05\nEpoch 14/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-05\nEpoch 15/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0399 - lr: 1.0000e-06\nEpoch 16/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-06\nEpoch 17/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0399 - lr: 1.0000e-06\nEpoch 18/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-06\nEpoch 19/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-07\nEpoch 20/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-07\nEpoch 21/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-07\nEpoch 22/200\n1375/1375 [==============================] - 5s 3ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-07\nEpoch 23/200\n1375/1375 [==============================] - 5s 4ms/step - loss: 0.0042 - mae: 0.0395 - val_loss: 0.0042 - val_mae: 0.0398 - lr: 1.0000e-08\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the median regressor\nhistory = median_regressor.fit(\n    x = X_train,\n    y = median_y_train,\n    batch_size = batch_size,\n    epochs = epochs,\n    validation_data=(X_val,median_y_val),\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, min_delta=5e-6, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=4, factor=0.1)\n    ]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:07:07.465029Z","iopub.execute_input":"2023-12-21T21:07:07.465759Z","iopub.status.idle":"2023-12-21T21:11:19.464131Z","shell.execute_reply.started":"2023-12-21T21:07:07.465720Z","shell.execute_reply":"2023-12-21T21:11:19.463126Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1/200\n1375/1375 [==============================] - 9s 5ms/step - loss: 0.0081 - mae: 0.0628 - val_loss: 0.0067 - val_mae: 0.0563 - lr: 0.0010\nEpoch 2/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0067 - mae: 0.0567 - val_loss: 0.0064 - val_mae: 0.0539 - lr: 0.0010\nEpoch 3/200\n1375/1375 [==============================] - 7s 5ms/step - loss: 0.0064 - mae: 0.0550 - val_loss: 0.0064 - val_mae: 0.0541 - lr: 0.0010\nEpoch 4/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0063 - mae: 0.0544 - val_loss: 0.0061 - val_mae: 0.0521 - lr: 0.0010\nEpoch 5/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0061 - mae: 0.0534 - val_loss: 0.0063 - val_mae: 0.0554 - lr: 0.0010\nEpoch 6/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0061 - mae: 0.0531 - val_loss: 0.0062 - val_mae: 0.0535 - lr: 0.0010\nEpoch 7/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0059 - mae: 0.0523 - val_loss: 0.0061 - val_mae: 0.0530 - lr: 0.0010\nEpoch 8/200\n1375/1375 [==============================] - 7s 5ms/step - loss: 0.0058 - mae: 0.0518 - val_loss: 0.0067 - val_mae: 0.0565 - lr: 0.0010\nEpoch 9/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0051 - mae: 0.0475 - val_loss: 0.0055 - val_mae: 0.0488 - lr: 1.0000e-04\nEpoch 10/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0050 - mae: 0.0470 - val_loss: 0.0055 - val_mae: 0.0486 - lr: 1.0000e-04\nEpoch 11/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0049 - mae: 0.0465 - val_loss: 0.0055 - val_mae: 0.0484 - lr: 1.0000e-04\nEpoch 12/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0049 - mae: 0.0463 - val_loss: 0.0054 - val_mae: 0.0484 - lr: 1.0000e-04\nEpoch 13/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0048 - mae: 0.0460 - val_loss: 0.0054 - val_mae: 0.0480 - lr: 1.0000e-04\nEpoch 14/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0048 - mae: 0.0457 - val_loss: 0.0053 - val_mae: 0.0480 - lr: 1.0000e-04\nEpoch 15/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0047 - mae: 0.0454 - val_loss: 0.0055 - val_mae: 0.0500 - lr: 1.0000e-04\nEpoch 16/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0047 - mae: 0.0451 - val_loss: 0.0053 - val_mae: 0.0476 - lr: 1.0000e-04\nEpoch 17/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0046 - mae: 0.0449 - val_loss: 0.0053 - val_mae: 0.0473 - lr: 1.0000e-04\nEpoch 18/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0045 - mae: 0.0439 - val_loss: 0.0052 - val_mae: 0.0473 - lr: 1.0000e-05\nEpoch 19/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0438 - val_loss: 0.0052 - val_mae: 0.0471 - lr: 1.0000e-05\nEpoch 20/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0437 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-05\nEpoch 21/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0437 - val_loss: 0.0052 - val_mae: 0.0472 - lr: 1.0000e-05\nEpoch 22/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0436 - val_loss: 0.0052 - val_mae: 0.0472 - lr: 1.0000e-05\nEpoch 23/200\n1375/1375 [==============================] - 6s 4ms/step - loss: 0.0044 - mae: 0.0436 - val_loss: 0.0052 - val_mae: 0.0471 - lr: 1.0000e-06\nEpoch 24/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-06\nEpoch 25/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0471 - lr: 1.0000e-06\nEpoch 26/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-06\nEpoch 27/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-07\nEpoch 28/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-07\nEpoch 29/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-07\nEpoch 30/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-07\nEpoch 31/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-08\nEpoch 32/200\n1375/1375 [==============================] - 7s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-08\nEpoch 33/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-08\nEpoch 34/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-08\nEpoch 35/200\n1375/1375 [==============================] - 6s 5ms/step - loss: 0.0044 - mae: 0.0435 - val_loss: 0.0052 - val_mae: 0.0470 - lr: 1.0000e-09\n","output_type":"stream"}]},{"cell_type":"code","source":"median_regressor.save(\"final_mr_18_stride10_all\")\nmodel_dlinear.save(\"final_DLinear_18_stride10_all\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:11:19.465711Z","iopub.execute_input":"2023-12-21T21:11:19.466082Z","iopub.status.idle":"2023-12-21T21:11:20.629198Z","shell.execute_reply.started":"2023-12-21T21:11:19.466046Z","shell.execute_reply":"2023-12-21T21:11:20.628260Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Predict the test set using the model\npredictions = model_dlinear.predict(norm_X_val)\npredicted_medians = median_regressor.predict(X_val)\n# Print the shape of the predictions\nprint(f\"Predictions shape: {predictions.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(norm_y_val.flatten(), predictions.flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(norm_y_val.flatten(), predictions.flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")\n\n# Print the shape of the regression\nprint(f\"Regressions shape: {predicted_medians.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(median_y_val.flatten(), predicted_medians.flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(median_y_val.flatten(), predicted_medians.flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")\n\nprint(f\"Predictions shape (DENORMALIZED USING regression VAL MEDIAN): {predictions.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:21:51.345593Z","iopub.execute_input":"2023-12-21T20:21:51.345845Z","iopub.status.idle":"2023-12-21T20:21:57.137641Z","shell.execute_reply.started":"2023-12-21T20:21:51.345823Z","shell.execute_reply":"2023-12-21T20:21:57.136753Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1369/1369 [==============================] - 2s 1ms/step\n1369/1369 [==============================] - 2s 1ms/step\nPredictions shape: (43793, 18)\nMean Squared Error: 0.003997802734375\nMean Absolute Error: 0.039276123046875\nRegressions shape: (43793, 1)\nMean Squared Error: 0.00487518310546875\nMean Absolute Error: 0.04583740234375\nPredictions shape (DENORMALIZED USING regression VAL MEDIAN): (43793, 18)\nMean Squared Error: 0.00809478759765625\nMean Absolute Error: 0.059295654296875\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## GRU model and training","metadata":{}},{"cell_type":"code","source":"def make_dataset(X, y, batch_size=128, prefetch_amt=tf.data.experimental.AUTOTUNE):\n    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n    # reshape x from (200) to (200,1) and y from (9) to (9,1)\n    dataset = dataset.map(lambda x, y: (tf.reshape(x, (200,1)), y),num_parallel_calls=tf.data.AUTOTUNE)\n    #dataset = dataset.shuffle(buffer_size=1024).batch(batch_size, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n    dataset = dataset.batch(batch_size, drop_remainder=False)\n    dataset = dataset.cache()\n    dataset = dataset.prefetch(prefetch_amt)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:21:57.138896Z","iopub.execute_input":"2023-12-21T20:21:57.139158Z","iopub.status.idle":"2023-12-21T20:21:57.145475Z","shell.execute_reply.started":"2023-12-21T20:21:57.139135Z","shell.execute_reply":"2023-12-21T20:21:57.144588Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"multi_lstm_model = tfk.Sequential([ #28,312 after 10 epochs\n    # Shape [batch, time, features] => [batch, lstm_units].\n    # Adding more `lstm_units` just overfits more quickly.\n    tfkl.GRU(200, return_sequences=True),\n    tfkl.GRU(200, return_sequences=False),\n    tfkl.Flatten(),\n    tfkl.Dense(telescope,kernel_initializer=tf.initializers.zeros()),\n])\nmulti_lstm_model.compile(loss=tfk.losses.MeanSquaredError(), metrics=['mae'], optimizer=tfk.optimizers.AdamW())\nmulti_lstm_model.build((None,window,1))\nmulti_lstm_model.summary() \nhistory = multi_lstm_model.fit(\n    make_dataset(norm_X_train, norm_y_train, batch_size=batch_size), #normalized_X_train\n    epochs = epochs,\n    validation_data=make_dataset(norm_X_val, norm_y_val, batch_size=batch_size),#(X_val,y_val),# (normalized_X_val,normalized_y_val)\n    callbacks = [\n        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=12, min_delta=5e-6, restore_best_weights=True),\n        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', patience=4, factor=0.1, min_lr=1e-7)\n    ]\n).history","metadata":{"execution":{"iopub.status.busy":"2023-12-21T20:21:57.146910Z","iopub.execute_input":"2023-12-21T20:21:57.147214Z","iopub.status.idle":"2023-12-21T20:40:37.175277Z","shell.execute_reply.started":"2023-12-21T20:21:57.147187Z","shell.execute_reply":"2023-12-21T20:40:37.174373Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n gru (GRU)                   (None, 200, 200)          121800    \n                                                                 \n gru_1 (GRU)                 (None, 200)               241200    \n                                                                 \n flatten (Flatten)           (None, 200)               0         \n                                                                 \n dense_5 (Dense)             (None, 18)                3618      \n                                                                 \n=================================================================\nTotal params: 366618 (1.40 MB)\nTrainable params: 366618 (1.40 MB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\nEpoch 1/200\n1369/1369 [==============================] - 37s 23ms/step - loss: 0.0049 - mae: 0.0431 - val_loss: 0.0046 - val_mae: 0.0426 - lr: 0.0010\nEpoch 2/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0046 - mae: 0.0419 - val_loss: 0.0044 - val_mae: 0.0408 - lr: 0.0010\nEpoch 3/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0044 - mae: 0.0408 - val_loss: 0.0042 - val_mae: 0.0397 - lr: 0.0010\nEpoch 4/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0042 - mae: 0.0400 - val_loss: 0.0041 - val_mae: 0.0396 - lr: 0.0010\nEpoch 5/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0042 - mae: 0.0398 - val_loss: 0.0041 - val_mae: 0.0395 - lr: 0.0010\nEpoch 6/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0042 - mae: 0.0396 - val_loss: 0.0041 - val_mae: 0.0392 - lr: 0.0010\nEpoch 7/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0041 - mae: 0.0393 - val_loss: 0.0040 - val_mae: 0.0389 - lr: 0.0010\nEpoch 8/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0041 - mae: 0.0390 - val_loss: 0.0039 - val_mae: 0.0384 - lr: 0.0010\nEpoch 9/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0040 - mae: 0.0387 - val_loss: 0.0039 - val_mae: 0.0379 - lr: 0.0010\nEpoch 10/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0040 - mae: 0.0385 - val_loss: 0.0039 - val_mae: 0.0379 - lr: 0.0010\nEpoch 11/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0039 - mae: 0.0384 - val_loss: 0.0038 - val_mae: 0.0376 - lr: 0.0010\nEpoch 12/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0039 - mae: 0.0382 - val_loss: 0.0038 - val_mae: 0.0376 - lr: 0.0010\nEpoch 13/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0039 - mae: 0.0380 - val_loss: 0.0038 - val_mae: 0.0375 - lr: 0.0010\nEpoch 14/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0038 - mae: 0.0379 - val_loss: 0.0038 - val_mae: 0.0380 - lr: 0.0010\nEpoch 15/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0038 - mae: 0.0377 - val_loss: 0.0037 - val_mae: 0.0374 - lr: 0.0010\nEpoch 16/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0037 - mae: 0.0366 - val_loss: 0.0036 - val_mae: 0.0364 - lr: 1.0000e-04\nEpoch 17/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0365 - val_loss: 0.0036 - val_mae: 0.0364 - lr: 1.0000e-04\nEpoch 18/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0364 - val_loss: 0.0036 - val_mae: 0.0363 - lr: 1.0000e-04\nEpoch 19/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0364 - val_loss: 0.0036 - val_mae: 0.0363 - lr: 1.0000e-04\nEpoch 20/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0364 - val_loss: 0.0036 - val_mae: 0.0362 - lr: 1.0000e-04\nEpoch 21/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0362 - lr: 1.0000e-05\nEpoch 22/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0362 - lr: 1.0000e-05\nEpoch 23/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0362 - lr: 1.0000e-05\nEpoch 24/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0362 - val_loss: 0.0036 - val_mae: 0.0362 - lr: 1.0000e-05\nEpoch 25/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-06\nEpoch 26/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-06\nEpoch 27/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-06\nEpoch 28/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-06\nEpoch 29/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 30/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 31/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 32/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 33/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 34/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 35/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 36/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\nEpoch 37/200\n1369/1369 [==============================] - 30s 22ms/step - loss: 0.0036 - mae: 0.0361 - val_loss: 0.0035 - val_mae: 0.0361 - lr: 1.0000e-07\n","output_type":"stream"}]},{"cell_type":"code","source":"multi_lstm_model.save(\"final_GRU_18_stride10_all\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:11:20.631277Z","iopub.execute_input":"2023-12-21T21:11:20.631585Z","iopub.status.idle":"2023-12-21T21:11:26.446140Z","shell.execute_reply.started":"2023-12-21T21:11:20.631553Z","shell.execute_reply":"2023-12-21T21:11:26.445268Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Predict the test set using the model\npredictions = multi_lstm_model.predict(np.expand_dims(norm_X_val,axis=-1))\npredicted_medians = median_regressor.predict(X_val)\n# Print the shape of the predictions\nprint(f\"Predictions shape: {predictions.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(norm_y_val.flatten(), predictions.flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(norm_y_val.flatten(), predictions.flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")\n\n# Print the shape of the regression\nprint(f\"Regressions shape: {predicted_medians.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(median_y_val.flatten(), predicted_medians.flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(median_y_val.flatten(), predicted_medians.flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")\n\nprint(f\"Predictions shape (DENORMALIZED USING regression VAL MEDIAN): {predictions.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:11:26.448709Z","iopub.execute_input":"2023-12-21T21:11:26.449017Z","iopub.status.idle":"2023-12-21T21:11:39.053289Z","shell.execute_reply.started":"2023-12-21T21:11:26.448989Z","shell.execute_reply":"2023-12-21T21:11:39.052256Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"1375/1375 [==============================] - 9s 6ms/step\n1375/1375 [==============================] - 2s 2ms/step\nPredictions shape: (43997, 18)\nMean Squared Error: 0.0037078857421875\nMean Absolute Error: 0.036529541015625\nRegressions shape: (43997, 1)\nMean Squared Error: 0.005218505859375\nMean Absolute Error: 0.047088623046875\nPredictions shape (DENORMALIZED USING regression VAL MEDIAN): (43997, 18)\nMean Squared Error: 0.00817108154296875\nMean Absolute Error: 0.0584716796875\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Ensemble results","metadata":{}},{"cell_type":"code","source":"#predict the val set using the ensemble\npred_gru = multi_lstm_model.predict(np.expand_dims(norm_X_val,axis=-1))\npred_dl = predictions = model_dlinear.predict(norm_X_val)\npredicted_medians = median_regressor.predict(X_val)\npredictions = (pred_gru+pred_dl)/2\nprint(f\"Predictions shape (DENORMALIZED USING regression VAL MEDIAN): {predictions.shape}\")\n# Calculate and print Mean Squared Error (MSE)\nmean_squared_error = tfk.metrics.mean_squared_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Squared Error: {mean_squared_error}\")\n# Calculate and print Mean Absolute Error (MAE)\nmean_absolute_error = tfk.metrics.mean_absolute_error(y_val.flatten(), (predictions+predicted_medians).flatten()).numpy()\nprint(f\"Mean Absolute Error: {mean_absolute_error}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:11:39.054665Z","iopub.execute_input":"2023-12-21T21:11:39.055029Z","iopub.status.idle":"2023-12-21T21:11:53.615913Z","shell.execute_reply.started":"2023-12-21T21:11:39.054995Z","shell.execute_reply":"2023-12-21T21:11:53.614947Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"1375/1375 [==============================] - 8s 6ms/step\n1375/1375 [==============================] - 2s 1ms/step\n1375/1375 [==============================] - 2s 1ms/step\nPredictions shape (DENORMALIZED USING regression VAL MEDIAN): (43997, 18)\nMean Squared Error: 0.00820159912109375\nMean Absolute Error: 0.058624267578125\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r final18_stride10_all.zip /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2023-12-21T21:11:53.617678Z","iopub.execute_input":"2023-12-21T21:11:53.618061Z","iopub.status.idle":"2023-12-21T21:11:55.612279Z","shell.execute_reply.started":"2023-12-21T21:11:53.618027Z","shell.execute_reply":"2023-12-21T21:11:55.611073Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/keras_metadata.pb (deflated 89%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/assets/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/saved_model.pb (deflated 90%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/variables/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/variables/variables.index (deflated 61%)\n  adding: kaggle/working/final_GRU_18_stride10_outlierrem/variables/variables.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/keras_metadata.pb (deflated 78%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/assets/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/saved_model.pb (deflated 85%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/variables/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/variables/variables.index (deflated 59%)\n  adding: kaggle/working/final_DLinear_18_stride10_all/variables/variables.data-00000-of-00001 (deflated 10%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/keras_metadata.pb (deflated 90%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/assets/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/saved_model.pb (deflated 87%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/variables/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/variables/variables.index (deflated 63%)\n  adding: kaggle/working/final_mr_18_stride10_outlierrem/variables/variables.data-00000-of-00001 (deflated 17%)\n  adding: kaggle/working/final18_stride10_outlierrem.zip (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_all/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_all/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_all/keras_metadata.pb (deflated 90%)\n  adding: kaggle/working/final_mr_18_stride10_all/assets/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_all/saved_model.pb (deflated 87%)\n  adding: kaggle/working/final_mr_18_stride10_all/variables/ (stored 0%)\n  adding: kaggle/working/final_mr_18_stride10_all/variables/variables.index (deflated 63%)\n  adding: kaggle/working/final_mr_18_stride10_all/variables/variables.data-00000-of-00001 (deflated 14%)\n  adding: kaggle/working/.virtual_documents/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_all/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_all/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_all/keras_metadata.pb (deflated 89%)\n  adding: kaggle/working/final_GRU_18_stride10_all/assets/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_all/saved_model.pb (deflated 90%)\n  adding: kaggle/working/final_GRU_18_stride10_all/variables/ (stored 0%)\n  adding: kaggle/working/final_GRU_18_stride10_all/variables/variables.index (deflated 61%)\n  adding: kaggle/working/final_GRU_18_stride10_all/variables/variables.data-00000-of-00001 (deflated 6%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/fingerprint.pb (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/keras_metadata.pb (deflated 78%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/assets/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/saved_model.pb (deflated 85%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/variables/ (stored 0%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/variables/variables.index (deflated 59%)\n  adding: kaggle/working/final_DLinear_18_stride10_outlierrem/variables/variables.data-00000-of-00001 (deflated 10%)\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'final18_stride10_all.zip')","metadata":{"execution":{"iopub.status.busy":"2023-12-22T00:44:04.563136Z","iopub.execute_input":"2023-12-22T00:44:04.563591Z","iopub.status.idle":"2023-12-22T00:44:04.596758Z","shell.execute_reply.started":"2023-12-22T00:44:04.563555Z","shell.execute_reply":"2023-12-22T00:44:04.595600Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/final18_stride10_all.zip","text/html":"<a href='final18_stride10_all.zip' target='_blank'>final18_stride10_all.zip</a><br>"},"metadata":{}}]}]}